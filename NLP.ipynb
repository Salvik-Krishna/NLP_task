{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Trip8U4MITGd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1360135bf2154af181e19ab01b1b418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a50d006367ee49c89c899a3eeceb5c36",
              "IPY_MODEL_66c05b73695c4a5686787700f2e7627a",
              "IPY_MODEL_9f652a5a0ed0466fa2afde20b3f4dc60"
            ],
            "layout": "IPY_MODEL_94b4391fabec476a94a89c7ddc931a7a"
          }
        },
        "a50d006367ee49c89c899a3eeceb5c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73888b624bf045f898124a6e1159751a",
            "placeholder": "​",
            "style": "IPY_MODEL_a1b091aaa1db4b5eb3f19ccc6dd93fdd",
            "value": "Epoch: 100%"
          }
        },
        "66c05b73695c4a5686787700f2e7627a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af367298a0ad416f912912b34955b399",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59c61f748c20477f9d981a516531a078",
            "value": 1
          }
        },
        "9f652a5a0ed0466fa2afde20b3f4dc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6bf3551483e442997e58fb724cad9bc",
            "placeholder": "​",
            "style": "IPY_MODEL_abf4096f1f254b57a4972a18937a2d66",
            "value": " 1/1 [07:23&lt;00:00, 443.15s/it]"
          }
        },
        "94b4391fabec476a94a89c7ddc931a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73888b624bf045f898124a6e1159751a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b091aaa1db4b5eb3f19ccc6dd93fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af367298a0ad416f912912b34955b399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c61f748c20477f9d981a516531a078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6bf3551483e442997e58fb724cad9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf4096f1f254b57a4972a18937a2d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a5b4e08adf94fa9b1137b8953f25e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_184c5f3536ad489ab20c3444d7408107",
              "IPY_MODEL_51eee318ad604adf9767ed4d5bb7038e",
              "IPY_MODEL_f72901880ecc44bf85872539d8cf3f85"
            ],
            "layout": "IPY_MODEL_20ae9644983c4878bc52a2e82c3f2e66"
          }
        },
        "184c5f3536ad489ab20c3444d7408107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02c62b39fd094e71a4ea0b04f1e57011",
            "placeholder": "​",
            "style": "IPY_MODEL_f92b385fc5a242c484ee3ad2ce3062e6",
            "value": "Iteration: 100%"
          }
        },
        "51eee318ad604adf9767ed4d5bb7038e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3f0fbc99354cf495fb3039ac88ae3d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf4cb80abe9f4a8d97fe9706db05c17c",
            "value": 10
          }
        },
        "f72901880ecc44bf85872539d8cf3f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3806f464bc954f74b76000203a41fe7c",
            "placeholder": "​",
            "style": "IPY_MODEL_585c10ee68944886935f379a5ad048da",
            "value": " 10/10 [07:23&lt;00:00, 44.00s/it]"
          }
        },
        "20ae9644983c4878bc52a2e82c3f2e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c62b39fd094e71a4ea0b04f1e57011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92b385fc5a242c484ee3ad2ce3062e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b3f0fbc99354cf495fb3039ac88ae3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4cb80abe9f4a8d97fe9706db05c17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3806f464bc954f74b76000203a41fe7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "585c10ee68944886935f379a5ad048da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1 -- NLP\n",
        "## Things to do:\n",
        "### *Coding* - Document work\n",
        "### *Paper*  - Summarize, 3 strength, weakness, improvement\n",
        "\n"
      ],
      "metadata": {
        "id": "xXKeyuHx0OtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Representations for Words, Phrases, Sentences\n",
        "NLP encompasses various tasks - Regression, Classification, Generation. A common denominator across all these tasks is the question of \"how do we convert text into numbers/representations\" so that machines can process them. One way to measure a machine's ability to “understand” text is Semantic Similarity i.e one should be able to tell you how similar or dissimilar are a given pair of text inputs - and this is the central theme of this task. You are expected to come up with solutions to the problems listed below. For all the tasks below, you can assess how well your solution is working based on some quantitative measures - you are expected to choose a metric that is suitable and justify\n",
        "the same.\n",
        "\n",
        "a. Word Similarity Scores: Given a pair of words, predict their similarity score. The focus is how do you convert a word to its numerical representation, on which learning algorithms (like Regression, classification etc) can be applied. Download the dataset from this link. You have to come up with an unsupervised / semi supervised method to achieve the task. Assume that you don't have any supervised training data at your disposal. The whole dataset will be used as a test set. Choose an appropriate metric that is suitable to assess the task and report the results. You have to come up with a solution for each of the following conditions:\n",
        "\n",
        "i. Constraints on Data Resources: You can only use the following resources\n",
        "(any one or all) to solve the problem (DON’T USE PRE-TRAINED MODELS!) :\n",
        "- any monolingual English corpus - Maximum 1 million tokens.\n",
        "- any curated/structured knowledge-bases / ontologies\n",
        "\n",
        "ii. Unconstrained : Consider that the constraints above are removed and you\n",
        "are allowed to use any data or model.\n",
        "Compare results/analysis across the two settings. What works, what doesn’t?\n",
        "And Why?\n",
        "\n",
        "b. Phrase and Sentence Similarity : In question (1) you would have come up with a method to get numerical/vector representation given a word. Now you have to come up with a mechanism to get representations for phrases and sentences. How do you aggregate individual word representations to get phrase or sentence embedding?\n",
        "- You can use any pretrained static word embeddings like word2vec,\n",
        "GLOVE, FASTTEXT etc, or create your own.\n",
        "- You can use popular tool/libraries (e.g nltk, Stanza, Spacy etc) to\n",
        "compute linguistic features (PoS, Constituency/Dependency Parse).\n",
        "i. Phrase Similarity : Given a pair of phrases classify whether or not they are similar. Dataset can be found here. Dataset has train/dev/test splits. You have to report results on the test set, and use train/dev sets as needed.\n",
        "ii. Sentence Similarity : Given a pair of sentences, classify whether or not they are similar. Dataset can be found here. Dataset has train/dev/test split. You have to report results on the test set. , and use train/dev sets as needed.\n",
        "You are encouraged to try multiple approaches to come up with phrase / sentence representations and models to solve the task, and do comparative analysis. What are the cases where your model fails - any patterns? Why so?\n",
        "\n",
        "c. BONUS TASK:\n",
        "i. Transformers are all the rage right now (backbone of most of the LLMs you might have used). Can you fine-tune a pre-trained transformer based models (BERT, Roberta, etc) to solve Phrase and Sentence Similarity Tasks described above? You are free to use any resource out there.\n",
        "ii. Can you prompt LLMs (ChatGPT, LLAMA) to solve the phrase and sentence similarity scores? Solve the task using\n",
        "1. commercial LLM APIs (ChatGPT, BARD etc);\n",
        "2. open source LLMs/APIs (LLAMA, Mistral etc).\n",
        "Try with zero and few shot settings. If querying LLMs is computational /\n",
        "commercially prohibitive, do it for only the test set / subset of test set. Analyze the results. Explain some analysis that you have done.\n",
        "iii. Compare all the approaches that you tried - static word embeddings, fine-tuned transformers, LLMs. What are the improvements you notice across the three settings?\n",
        "d. Paper Reading Task : BERTSCORE: EVALUATING TEXT GENERATION WITH BERT"
      ],
      "metadata": {
        "id": "Hsf362Ao2A2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tM7ABZJg85Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1\n"
      ],
      "metadata": {
        "id": "vqcycnuz9P_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Constrained Word Similarity"
      ],
      "metadata": {
        "id": "iMB3Ybh987xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "uY1WAsBW9IGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload Dataset\n",
        "uploaded_dataset_file_constrained_word_similarity = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "LuvO2hjw_AoM",
        "outputId": "99bea1a0-cbfa-417b-dc5d-cd9179bdb3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa3b7fff-50e2-4d4f-8ff9-169fc0c566a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa3b7fff-50e2-4d4f-8ff9-169fc0c566a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SimLex-999.txt to SimLex-999.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_constrained_word = pd.read_csv(io.BytesIO(uploaded_dataset_file_constrained_word_similarity['SimLex-999.txt']), delimiter='\\t')\n",
        "print(data_constrained_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x9qfy1D_HX-",
        "outputId": "efaff6b6-8aa7-44d1-d4ee-137f39266b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  \\\n",
            "0       old          new   A       1.58      2.72      2.81      2   \n",
            "1     smart  intelligent   A       9.20      1.75      2.46      1   \n",
            "2      hard    difficult   A       8.77      3.76      2.21      2   \n",
            "3     happy     cheerful   A       9.55      2.56      2.34      1   \n",
            "4      hard         easy   A       0.95      3.76      2.07      2   \n",
            "..      ...          ...  ..        ...       ...       ...    ...   \n",
            "994    join      acquire   V       2.85      2.86      2.93      2   \n",
            "995    send       attend   V       1.67      2.70      3.17      2   \n",
            "996  gather       attend   V       4.80      2.75      3.17      2   \n",
            "997  absorb     withdraw   V       2.97      3.11      3.04      2   \n",
            "998  attend       arrive   V       6.08      3.17      3.22      2   \n",
            "\n",
            "     Assoc(USF)  SimAssoc333  SD(SimLex)  \n",
            "0          7.25            1        0.41  \n",
            "1          7.11            1        0.67  \n",
            "2          5.94            1        1.19  \n",
            "3          5.85            1        2.18  \n",
            "4          5.82            1        0.93  \n",
            "..          ...          ...         ...  \n",
            "994        0.00            0        0.99  \n",
            "995        0.00            0        1.44  \n",
            "996        0.00            0        1.97  \n",
            "997        0.00            0        1.75  \n",
            "998        0.00            0        1.18  \n",
            "\n",
            "[999 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e4eQVib2_JcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5QqpJyo6_JR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unconstrained Word Similarity"
      ],
      "metadata": {
        "id": "dtSp2Hwu9Jag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Word2Vec"
      ],
      "metadata": {
        "id": "SCVuWjwPJPof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import gensim\n",
        "import os\n",
        "from scipy.stats import spearmanr\n",
        "import csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import spacy"
      ],
      "metadata": {
        "id": "wcHVr7NIE3Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_unconstrained_word2vec = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "mi_dj9fZN6eM",
        "outputId": "ec709ad9-f846-4ba7-e24e-3b1c22d92f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5465a099-8953-4ad9-a576-48b3520d7fb8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5465a099-8953-4ad9-a576-48b3520d7fb8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving word.csv to word.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uploaded_unconstrained_word = files.upload()\n",
        "# encyclopedia"
      ],
      "metadata": {
        "id": "tlVnpBiA1HzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Corpus(object):\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "        self.nlp = spacy.blank(\"en\")\n",
        "    def __iter__(self):\n",
        "        with open(self.filename, \"r\") as i:\n",
        "            reader = csv.reader(i, delimiter=\",\")\n",
        "            for _, abstract in reader:\n",
        "                tokens = [t.text.lower() for t in self.nlp(abstract)]\n",
        "                yield tokens\n",
        "documents = Corpus(\"word.csv\")"
      ],
      "metadata": {
        "id": "ddUzi8xxN6I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_unconstrained_word2vec = gensim.models.Word2Vec(documents, min_count=100, window=5, vector_size=200)"
      ],
      "metadata": {
        "id": "040W11xg21WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_unconstrained_word2vec.save('models/unconstrained_word2vec')"
      ],
      "metadata": {
        "id": "C4-ZIhkl4xDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_unconstrained_word2vec_path = 'models/unconstrained_word2vec'  # Path to your trained Word2Vec model\n",
        "model_unconstrained_word2vec = gensim.models.Word2Vec.load(model_unconstrained_word2vec_path)"
      ],
      "metadata": {
        "id": "M7PckB3snp9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_similarity(word1, word2, word_embeddings):\n",
        "    if word1 in word_embeddings.wv.key_to_index and word2 in word_embeddings.wv.key_to_index:\n",
        "        similarity_score = cosine_similarity(word_embeddings.wv[word1].reshape(1, -1), word_embeddings.wv[word2].reshape(1, -1))[0][0]\n",
        "        return similarity_score\n",
        "    return -1"
      ],
      "metadata": {
        "id": "LmT_M3YPpLHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_similarity(\"ml\", \"nlp\", model_unconstrained_word2vec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0MHxXrspbjd",
        "outputId": "0d2faa8f-d21a-4701-80ce-eb60a0e94e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5263437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simlex_copy=np.array(data_constrained_word)\n",
        "word_pairs = [(row[0], row[1]) for row in simlex_copy]\n",
        "\n",
        "simlex_ratings = [float(row[3]) for row in simlex_copy]\n",
        "simlex_ratings = [rating for rating in simlex_ratings]"
      ],
      "metadata": {
        "id": "pS0PTadfpbfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model_similarities = []\n",
        "filtered_word2vec_simlex_ratings = []\n",
        "for pair, rating in zip(word_pairs, simlex_ratings):\n",
        "    word1, word2 = pair\n",
        "    similarity_score = word_similarity(word1, word2, model_unconstrained_word2vec)\n",
        "    if similarity_score != -1:\n",
        "        word2vec_model_similarities.append(similarity_score * 10)\n",
        "        filtered_word2vec_simlex_ratings.append(rating)\n",
        "\n",
        "spearman_correlation, _ = spearmanr(filtered_word2vec_simlex_ratings, word2vec_model_similarities)\n",
        "print(\"Spearman correlation between word2vec model predictions and SimLex-999 ratings:\", spearman_correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCBxn4VzveZd",
        "outputId": "4fc2ff35-a64a-4f31-ed4f-695d16dbae1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman correlation between word2vec model predictions and SimLex-999 ratings: 0.20142711234786037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Glove using D2L data"
      ],
      "metadata": {
        "id": "Trip8U4MITGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "!pip install d2l\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "BlSANgAY9Okp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
        "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
        "\n",
        "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
        "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
        "\n",
        "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
        "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
        "\n",
        "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
        "                           'c1816da3821ae9f43899be655002f6c723e91b88')\n",
        "\n",
        "class TokenEmbedding:\n",
        "    \"\"\"Token Embedding.\"\"\"\n",
        "    def __init__(self, embedding_name):\n",
        "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
        "            embedding_name)\n",
        "        self.unknown_idx = 0\n",
        "        self.token_to_idx = {token: idx for idx, token in\n",
        "                             enumerate(self.idx_to_token)}\n",
        "\n",
        "    def _load_embedding(self, embedding_name):\n",
        "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
        "        data_dir = d2l.download_extract(embedding_name)\n",
        "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
        "            for line in f:\n",
        "                elems = line.rstrip().split(' ')\n",
        "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
        "                if len(elems) > 1:\n",
        "                    idx_to_token.append(token)\n",
        "                    idx_to_vec.append(elems)\n",
        "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
        "        return idx_to_token, torch.tensor(idx_to_vec)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
        "                   for token in tokens]\n",
        "        vecs = self.idx_to_vec[torch.tensor(indices)]\n",
        "        return vecs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)"
      ],
      "metadata": {
        "id": "PMKNDuC0E3lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_6b50d = TokenEmbedding('glove.6b.50d')"
      ],
      "metadata": {
        "id": "JN8qfBNSI_2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(W, x, k):\n",
        "    # Add 1e-9 for numerical stability\n",
        "    cos = torch.mv(W, x.reshape(-1,)) / (\n",
        "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\n",
        "        torch.sqrt((x * x).sum()))\n",
        "    _, topk = torch.topk(cos, k=k)\n",
        "    return topk, [cos[int(i)] for i in topk]\n",
        "\n",
        "def get_similar_tokens(query_token, k, embed):\n",
        "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
        "    for i, c in zip(topk[1:], cos[1:]):  # Exclude the input word\n",
        "        print(f'cosine sim={float(c):.3f}: {embed.idx_to_token[int(i)]}')"
      ],
      "metadata": {
        "id": "F_p0eIJJJHC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_similar_tokens('chip', 3, glove_6b50d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79BIaWXUkS34",
        "outputId": "9d27ebe9-eb7d-432e-fc5d-ad1a4f545508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cosine sim=0.856: chips\n",
            "cosine sim=0.749: intel\n",
            "cosine sim=0.749: electronics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparing both"
      ],
      "metadata": {
        "id": "PEN0mTFL9W5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3Pjp4nS9ahk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2"
      ],
      "metadata": {
        "id": "wldzmupM9pSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Phrase Similarity"
      ],
      "metadata": {
        "id": "EVcoax0o9t4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "jM4MtbVl9s73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "phrase_similarity_dataset = load_dataset(\"PiC/phrase_similarity\")"
      ],
      "metadata": {
        "id": "toJaomaVzAIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaeTlq2OFyr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6D4v7znVFyYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to Sentence Similarity Changing the dataset"
      ],
      "metadata": {
        "id": "IQdnowplm05k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentence Similarity\n",
        "\n"
      ],
      "metadata": {
        "id": "VXz6noEm9_T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "sentence_similarity_dataset = load_dataset(\"paws\", \"labeled_final\")"
      ],
      "metadata": {
        "id": "gQacU76_-Bn_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import datasets\n",
        "#nltk.download('stopwords')\n",
        "from datasets import load_dataset\n",
        "# import sys\n",
        "# sys.path.append(\"../../\")\n",
        "import os\n",
        "from collections import Counter\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tempfile import TemporaryDirectory\n",
        "# !pip install scrapbook\n",
        "import scrapbook as sb\n",
        "import scipy\n",
        "from scipy.spatial import distance\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "wvZMpb1-BL3W"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_similarity_train=pd.DataFrame(sentence_similarity_dataset['train'])\n",
        "sentence_similarity_test=pd.DataFrame(sentence_similarity_dataset['test'])\n",
        "sentence_similarity_dev=pd.DataFrame(sentence_similarity_dataset['validation'])"
      ],
      "metadata": {
        "id": "k31D-ailBZG2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_similarity_test.head(10)\n",
        "# with open('output.txt', 'a') as f:\n",
        "#     f.write(sentence_similarity_train[:100].to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5oVrOmWtBpQj",
        "outputId": "169c3f4d-c9b2-4de4-cbab-6006deb4534f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                          sentence1  \\\n",
              "0   1  This was a series of nested angular standards ...   \n",
              "1   2  His father emigrated to Missouri in 1868 but r...   \n",
              "2   3  In January 2011 , the Deputy Secretary General...   \n",
              "3   4  Steiner argued that , in the right circumstanc...   \n",
              "4   5  Luciano Williames Dias ( born July 25 , 1970 )...   \n",
              "5   6  During her sophomore , junior and senior summe...   \n",
              "6   7  The smallest number that can be represented in...   \n",
              "7   8  His father emigrated to Missouri in 1868 , but...   \n",
              "8   9  The Villa Pesquera facilities are owned by the...   \n",
              "9  10  It is situated south of Köroğlu Mountains and ...   \n",
              "\n",
              "                                           sentence2  label  \n",
              "0  This was a series of nested polar scales , so ...      0  \n",
              "1  His father emigrated to America in 1868 , but ...      0  \n",
              "2  In January 2011 , FIBA Asia deputy secretary g...      1  \n",
              "3  Steiner held that the spiritual world can be r...      0  \n",
              "4  Luciano Williames Dias ( born 25 July 1970 ) i...      0  \n",
              "5  During her second , junior and senior summers ...      1  \n",
              "6  The smallest number that can be represented as...      0  \n",
              "7  His father emigrated to Missouri in 1868 but r...      1  \n",
              "8  The facilities of Villa Pesquera are operated ...      0  \n",
              "9  It is situated south of Köroğlu - mountains an...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfd5ea57-5ba9-4cb2-95c7-33ebb4cf098c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>This was a series of nested angular standards ...</td>\n",
              "      <td>This was a series of nested polar scales , so ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>His father emigrated to Missouri in 1868 but r...</td>\n",
              "      <td>His father emigrated to America in 1868 , but ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>In January 2011 , the Deputy Secretary General...</td>\n",
              "      <td>In January 2011 , FIBA Asia deputy secretary g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Steiner argued that , in the right circumstanc...</td>\n",
              "      <td>Steiner held that the spiritual world can be r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Luciano Williames Dias ( born July 25 , 1970 )...</td>\n",
              "      <td>Luciano Williames Dias ( born 25 July 1970 ) i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>During her sophomore , junior and senior summe...</td>\n",
              "      <td>During her second , junior and senior summers ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>The smallest number that can be represented in...</td>\n",
              "      <td>The smallest number that can be represented as...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>His father emigrated to Missouri in 1868 , but...</td>\n",
              "      <td>His father emigrated to Missouri in 1868 but r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>The Villa Pesquera facilities are owned by the...</td>\n",
              "      <td>The facilities of Villa Pesquera are operated ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>It is situated south of Köroğlu Mountains and ...</td>\n",
              "      <td>It is situated south of Köroğlu - mountains an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfd5ea57-5ba9-4cb2-95c7-33ebb4cf098c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfd5ea57-5ba9-4cb2-95c7-33ebb4cf098c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfd5ea57-5ba9-4cb2-95c7-33ebb4cf098c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d965dee0-5a86-4027-9174-dc48a197dd4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d965dee0-5a86-4027-9174-dc48a197dd4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d965dee0-5a86-4027-9174-dc48a197dd4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#     f\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The Villa Pesquera facilities are owned by the Municipality of Ponce , but operated by the fishermen themselves .\",\n          \"His father emigrated to Missouri in 1868 but returned when his wife became ill and before the rest of the family could also go to America .\",\n          \"During her sophomore , junior and senior summers , she spent half of it with her Alaska team , and half playing , and living in Oregon .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The facilities of Villa Pesquera are operated by the Municipality of Ponce , but are owned by the fishermen .\",\n          \"His father emigrated to America in 1868 , but returned when his wife became ill and before the rest of the family could go to Missouri .\",\n          \"During her second , junior and senior summers , she spent half of it with her Alaska team , half playing and living in Oregon .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LRr-YbznHACG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1PH-ZL9n7u9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Hugging Face SentenceTransformer"
      ],
      "metadata": {
        "id": "4SfA4299HDf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, InputExample, models, losses, util\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "74xqBzumu82h"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=256)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2TXaD0Pum9G",
        "outputId": "6bea930b-b8b7-4622-a5b5-54f8056ad4b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=256)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "dense_model = models.Dense(\n",
        "    in_features=pooling_model.get_sentence_embedding_dimension(),\n",
        "    out_features=256,\n",
        "    activation_function=nn.Tanh(),\n",
        ")\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])"
      ],
      "metadata": {
        "id": "3PEIrtDGum2I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_input_examples(df_chunk):\n",
        "    examples = []\n",
        "    for index, row in df_chunk.iterrows():\n",
        "        text1 = row['sentence1']\n",
        "        text2 = row['sentence2']\n",
        "        label = float(row['label'])\n",
        "        examples.append(InputExample(texts=[text1, text2], label=label))\n",
        "    return examples\n",
        "chunk_size = 100\n",
        "\n",
        "train_examples_sentence = []\n",
        "dev_examples_sentence = []\n",
        "test_examples_sentence = []\n",
        "\n",
        "for i in range(10):\n",
        "    start_idx = i * chunk_size\n",
        "    end_idx = min((i + 1) * chunk_size, 1000)\n",
        "    df_chunk = sentence_similarity_test[start_idx:end_idx]\n",
        "    examples_chunk = dataframe_to_input_examples(df_chunk)\n",
        "    train_examples_sentence.extend(examples_chunk)\n",
        "\n",
        "dev_examples_sentence = []\n",
        "for i in range(5):\n",
        "    start_idx = i * chunk_size\n",
        "    end_idx = min((i + 1) * chunk_size, 500)\n",
        "    df_chunk = sentence_similarity_dev[start_idx:end_idx]\n",
        "    examples_chunk = dataframe_to_input_examples(df_chunk)\n",
        "    dev_examples_sentence.extend(examples_chunk)\n",
        "\n",
        "\n",
        "test_examples_sentence = []\n",
        "for i in range(5):\n",
        "    start_idx = i * chunk_size\n",
        "    end_idx = min((i + 1) * chunk_size, 500)\n",
        "    df_chunk = sentence_similarity_train[start_idx:end_idx]\n",
        "    examples_chunk = dataframe_to_input_examples(df_chunk)\n",
        "    test_examples_sentence.extend(examples_chunk)"
      ],
      "metadata": {
        "id": "apo2rQDU8yb1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"distilbert-base-nli-mean-tokens\")\n",
        "# train_examples = [\n",
        "#     InputExample(texts=[\"My first sentence\", \"My second sentence\"], label=0.8),\n",
        "# ]\n",
        "train_dataloader = DataLoader(train_examples_sentence, shuffle=True, batch_size=100)"
      ],
      "metadata": {
        "id": "W-zVlvrRumwE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "1360135bf2154af181e19ab01b1b418e",
            "a50d006367ee49c89c899a3eeceb5c36",
            "66c05b73695c4a5686787700f2e7627a",
            "9f652a5a0ed0466fa2afde20b3f4dc60",
            "94b4391fabec476a94a89c7ddc931a7a",
            "73888b624bf045f898124a6e1159751a",
            "a1b091aaa1db4b5eb3f19ccc6dd93fdd",
            "af367298a0ad416f912912b34955b399",
            "59c61f748c20477f9d981a516531a078",
            "b6bf3551483e442997e58fb724cad9bc",
            "abf4096f1f254b57a4972a18937a2d66",
            "8a5b4e08adf94fa9b1137b8953f25e2d",
            "184c5f3536ad489ab20c3444d7408107",
            "51eee318ad604adf9767ed4d5bb7038e",
            "f72901880ecc44bf85872539d8cf3f85",
            "20ae9644983c4878bc52a2e82c3f2e66",
            "02c62b39fd094e71a4ea0b04f1e57011",
            "f92b385fc5a242c484ee3ad2ce3062e6",
            "4b3f0fbc99354cf495fb3039ac88ae3d",
            "bf4cb80abe9f4a8d97fe9706db05c17c",
            "3806f464bc954f74b76000203a41fe7c",
            "585c10ee68944886935f379a5ad048da"
          ]
        },
        "id": "OgIhOxFNummh",
        "outputId": "718ededc-1b4d-4054-d77c-9d99a0fe08e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1360135bf2154af181e19ab01b1b418e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iteration:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a5b4e08adf94fa9b1137b8953f25e2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"models/sentence\")"
      ],
      "metadata": {
        "id": "3eeUSkXU6nMy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_similarity_test1=sentence_similarity_test[:500]\n",
        "test_encodings1 = model.encode(sentence_similarity_test1['sentence1'].tolist())\n",
        "test_encodings2 = model.encode(sentence_similarity_test1['sentence2'].tolist())"
      ],
      "metadata": {
        "id": "LbWbQSUZGsMm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"This is the first sentence.\"\n",
        "sentence2 = \"This is the second sentence.\"\n",
        "# Encode sentences\n",
        "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
        "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
        "error=0\n",
        "for i in range(500):\n",
        "  error=(error*(i)+(sentence_similarity_test1['label'][i]-(util.pytorch_cos_sim(test_encodings1[i], test_encodings2[i])).item()))/(i+1)\n",
        "print(\"Error:\", error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51dj6OaRI_Br",
        "outputId": "69f1deea-fbe1-4618-8535-ca72354e73f1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: -0.5355040491819378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For large corpus we can use Pragraph mining"
      ],
      "metadata": {
        "id": "U7yw2P22mdah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bonus Task"
      ],
      "metadata": {
        "id": "57qHiFzV-K4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine Tune Transformer"
      ],
      "metadata": {
        "id": "rXpXmJa4-OpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Using BERT"
      ],
      "metadata": {
        "id": "5ZF8LgOko4hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers datasets\n",
        "!pip install dataset\n",
        "!pip install transformers\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from transformers import BertTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "47QNgTMvo4PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "yPZO5zuypzcg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"stsb_multi_mt\", \"en\")"
      ],
      "metadata": {
        "id": "t9f3biFZo2v5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "K5JQNT1n-M87"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class STSBDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "\n",
        "        # Normalize the similarity scores in the dataset\n",
        "        similarity_scores = [i['similarity_score'] for i in dataset]\n",
        "        self.normalized_similarity_scores = [i/5.0 for i in similarity_scores]\n",
        "        self.first_sentences = [i['sentence1'] for i in dataset]\n",
        "        self.second_sentences = [i['sentence2'] for i in dataset]\n",
        "        self.concatenated_sentences = [[str(x), str(y)] for x,y in zip(self.first_sentences, self.second_sentences)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.concatenated_sentences)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        return torch.tensor(self.normalized_similarity_scores[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        return tokenizer(self.concatenated_sentences[idx], padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_y\n",
        "\n",
        "\n",
        "def collate_fn(texts):\n",
        "    input_ids = texts['input_ids']\n",
        "    attention_masks = texts['attention_mask']\n",
        "    features = [{'input_ids': input_id, 'attention_mask': attention_mask}\n",
        "                for input_id, attention_mask in zip(input_ids, attention_masks)]\n",
        "    return features\n",
        "\n",
        "class BertForSTS(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BertForSTS, self).__init__()\n",
        "        self.bert = models.Transformer('bert-base-uncased', max_seq_length=128)\n",
        "        self.pooling_layer = models.Pooling(self.bert.get_word_embedding_dimension())\n",
        "        self.sts_bert = SentenceTransformer(modules=[self.bert, self.pooling_layer])\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        output = self.sts_bert(input_data)['sentence_embedding']\n",
        "        return output"
      ],
      "metadata": {
        "id": "_XuDu7PNpdjG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSTS()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "vs9PZFwYpdgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineSimilarityLoss(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,  loss_fn=torch.nn.MSELoss(), transform_fn=torch.nn.Identity()):\n",
        "        super(CosineSimilarityLoss, self).__init__()\n",
        "        self.loss_fn = loss_fn\n",
        "        self.transform_fn = transform_fn\n",
        "        self.cos_similarity = torch.nn.CosineSimilarity(dim=1)\n",
        "\n",
        "    def forward(self, inputs, labels):\n",
        "        emb_1 = torch.stack([inp[0] for inp in inputs])\n",
        "        emb_2 = torch.stack([inp[1] for inp in inputs])\n",
        "        outputs = self.transform_fn(self.cos_similarity(emb_1, emb_2))\n",
        "        return self.loss_fn(outputs, labels.squeeze())\n",
        "\n",
        "train_ds = STSBDataset(dataset['train'])\n",
        "val_ds = STSBDataset(dataset['dev'])\n",
        "\n",
        "train_size = len(train_ds)\n",
        "val_size = len(val_ds)\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            train_ds,  # The training samples.\n",
        "            num_workers = 4,\n",
        "            batch_size = batch_size, # Use this batch size.\n",
        "            shuffle=True # Select samples randomly for each batch\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_ds,\n",
        "            num_workers = 4,\n",
        "            batch_size = batch_size # Use the same batch size\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEoZhuscpdcR",
        "outputId": "4792307a-8951-41db-ce0a-b5903389626f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5,749 training samples\n",
            "1,500 validation samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-6)\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "fa6Wvj_epdZi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training in data: Can be skipped afterward as our model is trained\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def train():\n",
        "  seed_val = 42\n",
        "\n",
        "  criterion = CosineSimilarityLoss()\n",
        "  criterion = criterion.to(device)\n",
        "\n",
        "  random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "\n",
        "  # We'll store a number of quantities such as training and validation loss,\n",
        "  # validation accuracy, and timings.\n",
        "  training_stats = []\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "\n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      total_train_loss = 0\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      # For each batch of training data...\n",
        "      for train_data, train_label in tqdm(train_dataloader):\n",
        "\n",
        "          train_data['input_ids'] = train_data['input_ids'].to(device)\n",
        "          train_data['attention_mask'] = train_data['attention_mask'].to(device)\n",
        "\n",
        "          train_data = collate_fn(train_data)\n",
        "          model.zero_grad()\n",
        "\n",
        "          output = [model(feature) for feature in train_data]\n",
        "\n",
        "          loss = criterion(output, train_label.to(device))\n",
        "          total_train_loss += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "      # Measure how long this epoch took.\n",
        "      training_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
        "      print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "\n",
        "      # Evaluate data for one epoch\n",
        "      for val_data, val_label in tqdm(validation_dataloader):\n",
        "\n",
        "          val_data['input_ids'] = val_data['input_ids'].to(device)\n",
        "          val_data['attention_mask'] = val_data['attention_mask'].to(device)\n",
        "\n",
        "          val_data = collate_fn(val_data)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              output = [model(feature) for feature in val_data]\n",
        "\n",
        "          loss = criterion(output, val_label.to(device))\n",
        "          total_eval_loss += loss.item()\n",
        "\n",
        "      # Calculate the average loss over all of the batches.\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "      # Measure how long the validation run took.\n",
        "      validation_time = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"  Validation Loss: {0:.5f}\".format(avg_val_loss))\n",
        "      print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "      # Record all statistics from this epoch.\n",
        "      training_stats.append(\n",
        "          {\n",
        "              'epoch': epoch_i + 1,\n",
        "              'Training Loss': avg_train_loss,\n",
        "              'Valid. Loss': avg_val_loss,\n",
        "              'Training Time': training_time,\n",
        "              'Validation Time': validation_time\n",
        "          }\n",
        "      )\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "  return model, training_stats\n",
        "  model, training_stats = train()\n",
        "# Create a DataFrame from our training statistics\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table\n",
        "df_stats"
      ],
      "metadata": {
        "id": "Ajc49uKzwChH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = load_dataset(\"stsb_multi_mt\", name=\"en\", split=\"test\")\n",
        "\n",
        "first_sent = [i['sentence1'] for i in test_dataset]\n",
        "second_sent = [i['sentence2'] for i in test_dataset]\n",
        "full_text = [[str(x), str(y)] for x,y in zip(first_sent, second_sent)]"
      ],
      "metadata": {
        "id": "qIKgaMY9vmfr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "def predict_similarity(sentence_pair):\n",
        "  test_input = tokenizer(sentence_pair, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\").to(device)\n",
        "  test_input['input_ids'] = test_input['input_ids']\n",
        "  test_input['attention_mask'] = test_input['attention_mask']\n",
        "  del test_input['token_type_ids']\n",
        "  output = model(test_input)\n",
        "  sim = torch.nn.functional.cosine_similarity(output[0], output[1], dim=0).item()\n",
        "\n",
        "  return sim"
      ],
      "metadata": {
        "id": "6DgMDu6stYdr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_2 = full_text[130]\n",
        "print(f\"Sentence 1: {example_2[0]}\")\n",
        "print(f\"Sentence 2: {example_2[1]}\")\n",
        "print(f\"Predicted similarity score: {round(predict_similarity(example_2), 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApfaSTHIuAXe",
        "outputId": "07010e08-4c2c-40e5-8e4d-798d0748d3f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1: Two men are playing football.\n",
            "Sentence 2: Two men are practicing football.\n",
            "Predicted similarity score: 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt LLM"
      ],
      "metadata": {
        "id": "o27RX-ZP-cX6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Commercial bardapi"
      ],
      "metadata": {
        "id": "SQF3-42x-mcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bardapi\n",
        "! pip install git+https://github.com/dsdanielpark/Bard-API.git"
      ],
      "metadata": {
        "id": "KaaiaVmZ-lp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bardapi\n",
        "import os\n",
        "\n",
        "# set your __Secure-1PSID value to key\n",
        "token = 'xxxxxxxxxx'\n",
        "\n",
        "# set your input text\n",
        "input_text = \"Hello\"\n",
        "\n",
        "# Send an API request and get a response.\n",
        "response = bardapi.core.Bard(token).get_answer(input_text)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4uPnvOQzADh",
        "outputId": "af4e02f7-540c-44ff-e3fb-d3b287870146"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'content': 'Response Error: b\\')]}\\\\\\'\\\\n\\\\n38\\\\n[[\"wrb.fr\",null,null,null,null,[7]]]\\\\n54\\\\n[[\"di\",39],[\"af.httprm\",38,\"3346129587758524624\",0]]\\\\n25\\\\n[[\"e\",4,null,null,129]]\\\\n\\'. \\nUnable to get response.\\nPlease double-check the cookie values and verify your network environment or google account.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatGPT https://chat.openai.com/share/04375dc5-9265-4f59-8b8c-840b6f750ed5"
      ],
      "metadata": {
        "id": "yO3yqTkE5Um6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "data = {\n",
        "    'id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
        "    'sentence1': [\n",
        "        \"In Paris , in October 1560 , he secretly met the English ambassador , Nicolas Throckmorton , asking him for a passport to return to England through Scotland .\",\n",
        "        \"The NBA season of 1975 -- 76 was the 30th season of the National Basketball Association .\",\n",
        "        \"There are also specific discussions , public profile debates and project discussions .\",\n",
        "        \"When comparable rates of flow can be maintained , the results are high .\",\n",
        "        \"It is the seat of Zerendi District in Akmola Region .\",\n",
        "        \"William Henry Henry Harman was born on 17 February 1828 in Waynesboro , Virginia , where his parents were Lewis and Sally ( Garber ) Harman .\",\n",
        "        \"Bullion Express - concept is being introduced new store in Dallas , Texas in Preston Center opened .\",\n",
        "        \"With a discrete amount of probabilities Formula 1 with the condition formula 2 and Formula 3 any real number , the Tsallis is defined as entropy as\",\n",
        "        \"The Soviet Union maintained an embassy in Oslo and a consulate in Barentsburg , while Norway maintained a message in Moscow .\",\n",
        "        \"Vocabulary even went to Brazil through leaving Portuguese settlers with some Macanese and Chinese settlers .\",\n",
        "        \"Kabir Suman recorded several albums under the name of Suman Chattopaddhyay or Suman Chatterjee between 1992 and 1999 .\",\n",
        "        \"He was a scholar in Metaphysical Literature , Theology and Classical sciences .\",\n",
        "        \"The city sits at the confluence of the Snake River with the great Weiser River , which marks the border with Oregon .\",\n",
        "        \"He has been trained by his grandfather , Nick Dakin , and is now trained by Geoff Barraclough .\",\n",
        "        \"The Austrian school assumes that the subjective choices of individuals , including individual knowledge , time , expectations , and other subjective factors , cause all economic phenomena .\",\n",
        "        \"Werder 's forces invested Belfort and reached the city on 3 November .\",\n",
        "        \"The kBox facilitates both isometric and concentric contractions as well as eccentric training .\",\n",
        "        \"The first five weapons were delivered in the first half of 1916 , with a total of 57 barrels and 56 cars completed by the end of the war .\",\n",
        "        \"Elizabeth II was an ancestor of Queens Edzard II and Beatrix of the Netherlands .\",\n",
        "        \"The friendship between him and Duncan ended at a club meeting in 1951 when the two disagreed at an annual meeting and Duncan reported that Greaves said :\",\n",
        "        \"Pluto was classified as the planet when the Grand Tour was proposed and was launched at the time `` New Horizons '' .\",\n",
        "        \"For their performances in the game , quarterback Jameis Winston and defensive back P. J. Williams were named the game 's most valuable players .\",\n",
        "        \"Shaffer Creek is a tributary of the Raystown Branch Juniata River ( Brush Creek ) in Bedford County , Pennsylvania , United States .\",\n",
        "        \"Kevin Spacey ( Henry Drummond ) and David Troughton ( Matthew Harrison Brady ) starred in a 2009 revival at The Old Vic in London .\",\n",
        "        \"Briggs later met Briggs at the 1967 Monterey Pop Festival , where Ravi Shankar was also performing , with Eric Burdon and The Animals .\",\n",
        "        \"Laura Myntti was born in Salt Lake City and lived in Sioux City , Iowa and San Diego before settling in Minnesota in 1968 .\",\n",
        "        \"The female lead role was played by Cortez in `` Ali Baba and the Sacred Crown '' , directed by Erminio Salvi .\",\n",
        "        \"She worked and lived in Stuttgart , Berlin ( Germany ) and in Vienna ( Austria ) .\",\n",
        "        \"Akshuat dendropark ( Russian : Акшуатский дендропарк ) is a natural monument ( Ulyanovsk Oblast protected areas )\",\n",
        "        \"The Little Jocko River flows across the Saint Lawrence River and the Ottawa River to the Jocko River .\",\n",
        "        \"In 1951 , he died and retired in 1956 .\"\n",
        "    ],\n",
        "    'sentence2': [\n",
        "        \"In October 1560 , he secretly met with the English ambassador , Nicolas Throckmorton , in Paris , and asked him for a passport to return to Scotland through England .\",\n",
        "        \"The 1975 -- 76 season of the National Basketball Association was the 30th season of the NBA .\",\n",
        "        \"There are also public discussions , profile specific discussions , and project discussions .\",\n",
        "        \"The results are high when comparable flow rates can be maintained .\",\n",
        "        \"It is the seat of the district of Zerendi in Akmola region .\",\n",
        "        \"William Henry Harman was born in Waynesboro , Virginia on February 17 , 1828 . His parents were Lewis and Sally ( Garber ) Harman .\",\n",
        "        \"2011-DGSE Bullion Express concept is introduced , new store opened in Preston Center in Dallas , Texas\",\n",
        "        \"Given a discrete set of probabilities formula _ 1 with the condition formula _ 2 , and formula _ 3 any real number , the Tsallis entropy is defined as\",\n",
        "        \"The Soviet Union maintained an embassy in Moscow and a consulate in Barentsburg , while Norway maintained a message in Oslo .\",\n",
        "        \"Vocabulary even went to Brazil by leaving Macanese and Chinese settlers with some Portuguese settlers .\",\n",
        "        \"Suman Chatterjee , recorded a number of albums between 1992 and 1999 under the name Suman Chattopaddhyay or Kabir Suman .\",\n",
        "        \"He was a scholar in metaphysical literature , theology , and classical science .\",\n",
        "        \"The city lies at the confluence of the Snake River and the Great Weiser River , which marks the border with Oregon .\",\n",
        "        \"He has been trained by his grandfather , Geoff Barraclough , and is now coached by Nick Dakin .\",\n",
        "        \"The Austrian school assumes that the subjective choices of individuals , including subjective knowledge , time , expectation , and other individual factors , cause all economic phenomena .\",\n",
        "        \"Werder 's troops invested Belfort and reached the city on November 3 .\",\n",
        "        \"The kBox facilitates eccentric as well as concentric contractions and isometric training .\",\n",
        "        \"The first five weapons were delivered in the first half of 1916 . A total of 57 barrels and 56 carriages were completed by the end of the war .\",\n",
        "        \"Edzard II was an ancestor of the Queens Elizabeth II and the Beatrix of the Netherlands .\",\n",
        "        \"The friendship between him and Duncan ended in 1951 at a club meeting , when the two did not agree at an annual meeting , and Duncan reported that Greaves said :\",\n",
        "        \"Note : Pluto was classified as a planet when the Grand Tour was launched and at the time `` New Horizons '' was proposed .\",\n",
        "        \"Quarterback P. J. Williams and Defensive Back Jameis Winston were named the most valuable players of the game for their performances in the game .\",\n",
        "        \"Shaffer Creek is an tributary of Brush Creek ( Raystown Branch Juniata River ) in Bedford County , Pennsylvania in the United States .\",\n",
        "        \"Kevin Spacey ( Henry Drummond ) and David Troughton ( Matthew Harrison Brady ) played in a resume in 2009 at the Old Vic London .\",\n",
        "        \"Briggs met Briggs later at the Monterey Pop Festival of 1967 , where Ravi Shankar also performed with Eric Burdon and The Animals .\",\n",
        "        \"Born in Minnesota , Laura Myntti lived in Sioux City , Iowa and San Diego , before settling in Salt Lake City in 1968 .\",\n",
        "        \"Cortez played the female lead in `` Ali Baba and the Sacred Crown '' , directed by Erminio Salvi .\",\n",
        "        \"She worked and lived in Germany ( Stuttgart , Berlin ) and in Vienna ( Austria ) .\",\n",
        "        \"Akshuat dendropark ( Russian : Акшуатский дендропарк ) is a natural monument ( Protected areas of Ulyanovsk Oblast )\",\n",
        "        \"The Little Jocko River flows via the Saint Lawrence River and the Ottawa River to the Jocko River .\",\n",
        "        \"He died in 1951 and retired in 1956 .\"\n",
        "    ],\n",
        "    'label': [0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Function to calculate cosine similarity\n",
        "def calculate_similarity(sentence1, sentence2):\n",
        "    vectorizer = CountVectorizer().fit_transform([sentence1, sentence2])\n",
        "    vectors = vectorizer.toarray()\n",
        "    return cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
        "\n",
        "# Calculate cosine similarity for each pair of sentences\n",
        "similarities = []\n",
        "for index, row in df.iterrows():\n",
        "    similarity = calculate_similarity(row['sentence1'], row['sentence2'])\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Check for errors\n",
        "errors = 0\n",
        "for i, label in enumerate(df['label']):\n",
        "    if label == 0 and similarities[i] >= 0.5:\n",
        "        errors += 1\n",
        "    elif label == 1 and similarities[i] < 0.5:\n",
        "        errors += 1\n",
        "\n",
        "# Report errors\n",
        "print(\"Total errors found:\", errors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwnRegFu5LIz",
        "outputId": "92ada181-7f47-4f22-d7a9-843443026a1f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total errors found: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Open Source"
      ],
      "metadata": {
        "id": "Q3FMhnqm-pTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"accelerate>=0.16.0,<1\" \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\"\n",
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "qRUPyeGy-rF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYwjMAxk_5tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n",
        "res = generate_text(\"Give semantic similarity label for 'This is first', 'This is second'\")\n",
        "print(res[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "tmY-Nkug_5rA",
        "outputId": "e9af90be-e141-4545-dac1-ae3ec190a361"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f52b32bd2692>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"databricks/dolly-v2-3b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Give semantic similarity label for 'This is first', 'This is second'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    789\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2903\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2904\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3244\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshard_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisk_only_shard_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3245\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3246\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3248\u001b[0m                 \u001b[0;31m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntyped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OqFPfx6G_5oz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}